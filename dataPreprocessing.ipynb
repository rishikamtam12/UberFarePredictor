{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:17.635677Z",
     "start_time": "2024-11-20T20:51:16.936382Z"
    }
   },
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# reading cab rides data into dataframe\n",
    "rides_df = pd.read_csv('dataOriginal/cab_rides.csv')\n",
    "\n",
    "# reading weather data into dataframe\n",
    "weather_df = pd.read_csv('dataOriginal/weather.csv')"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:17.689515Z",
     "start_time": "2024-11-20T20:51:17.642430Z"
    }
   },
   "source": [
    "# Converting Unix timestamp to Datetime, truncated to nearest hour\n",
    "rides_df['time_stamp'] = pd.to_datetime(rides_df['time_stamp'], unit='ms').dt.floor('h')\n",
    "weather_df['time_stamp'] = pd.to_datetime(rides_df['time_stamp'], unit='ms').dt.floor('h')\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:20.954398Z",
     "start_time": "2024-11-20T20:51:20.814867Z"
    }
   },
   "source": [
    "# removing Null Values from rides dataframe \n",
    "rides_df = rides_df.dropna()\n",
    "\n",
    "# Remove product id from rides df\n",
    "rides_df = rides_df.drop('product_id', axis = 1)\n",
    "\n",
    "# Converting id from 30 characters -> 0, 1, 2, etc..\n",
    "rides_df['id'] = range(len(rides_df))\n",
    "\n",
    "\n",
    "# converting null values in (rain) column to 0 (No rain)\n",
    "weather_df['rain'] = weather_df['rain'].fillna(0)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.1228\n",
       "1     0.1846\n",
       "2     0.1089\n",
       "3     0.0969\n",
       "4     0.1786\n",
       "5     0.2068\n",
       "6     0.2088\n",
       "7     0.2069\n",
       "8     0.1020\n",
       "9     0.1547\n",
       "10    0.1428\n",
       "11    0.0000\n",
       "12    0.0000\n",
       "13    0.0000\n",
       "14    0.0000\n",
       "15    0.0000\n",
       "16    0.0000\n",
       "17    0.0000\n",
       "18    0.0000\n",
       "19    0.0000\n",
       "Name: rain, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:28.495967Z",
     "start_time": "2024-11-20T20:51:28.407994Z"
    }
   },
   "source": [
    "# splitting dataframes into Uber and Lyft\n",
    "uber_df = rides_df[rides_df['cab_type'] == 'Uber']\n",
    "lyft_df = rides_df[rides_df['cab_type'] == 'Lyft']"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:30.712215Z",
     "start_time": "2024-11-20T20:51:29.244726Z"
    }
   },
   "source": [
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client.from_service_account_json(\"secrets/serviceKey.json\")\n",
    "\n",
    "# Define the dataset reference\n",
    "project_id = \"idmpproject-441123\"\n",
    "dataset_id = \"uberFareEstimation\"\n",
    "dataset_ref = f\"{project_id}.{dataset_id}\"\n",
    "\n",
    "# List all tables in the dataset\n",
    "tablesList = []\n",
    "try:\n",
    "    tables = client.list_tables(dataset_ref)\n",
    "    print(f\"Tables in dataset {dataset_id}:\")\n",
    "    for table in tables:\n",
    "        tablesList.append(table.table_id)\n",
    "        print(table.table_id)\n",
    "except NotFound:\n",
    "    print(f\"Dataset {dataset_id} does not exist.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in dataset uberFareEstimation:\n",
      "lyft_data\n",
      "uber_data\n",
      "weather_data\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:31.273418Z",
     "start_time": "2024-11-20T20:51:31.269869Z"
    }
   },
   "source": [
    "rides_schema = [\n",
    "    bigquery.SchemaField(\"distance\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cab_type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"time_stamp\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"destination\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"source\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"price\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"surge_multiplier\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"name\", \"STRING\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "weather_schema = [\n",
    "    bigquery.SchemaField(\"temp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"location\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"clouds\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"pressure\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"rain\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"time_stamp\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"humidity\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"wind\", \"FLOAT\", mode=\"NULLABLE\")\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:25.959090Z",
     "start_time": "2024-11-20T20:52:25.952156Z"
    }
   },
   "source": [
    "if 'uber_data' not in tablesList:\n",
    "    table_id = \"uber_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    table_object = bigquery.Table(table_ref, schema=rides_schema)\n",
    "    try:\n",
    "        table = client.create_table(table_object)\n",
    "        print(f\"Created empty table {table_id} in dataset {dataset_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "\n",
    "if 'lyft_data' not in tablesList:\n",
    "    table_id = \"lyft_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    table_object = bigquery.Table(table_ref, schema=rides_schema)\n",
    "    try:\n",
    "        table = client.create_table(table_object)\n",
    "        print(f\"Created empty table {table_id} in dataset {dataset_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "        \n",
    "        \n",
    "if 'weather_data' not in tablesList:\n",
    "    table_id = \"weather_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    table_object = bigquery.Table(table_ref, schema=rides_schema)\n",
    "    try:\n",
    "        table = client.create_table(table_object)\n",
    "        print(f\"Created empty table {table_id} in dataset {dataset_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:26.963413Z",
     "start_time": "2024-11-20T20:52:26.960251Z"
    }
   },
   "source": [
    "def overWriteDataToTable(dataFrameName, table_ref):\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\",  # Append the data to the table\n",
    "    )\n",
    "    job = client.load_table_from_dataframe(dataFrameName, table_ref, job_config=job_config)\n",
    "\n",
    "    # Wait for the job to complete\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Over written {len(rides_df)} rows to the table {table_id} in dataset {dataset_id}.\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:31.756397Z",
     "start_time": "2024-11-20T20:52:28.538313Z"
    }
   },
   "source": [
    "while True:\n",
    "    user_input = input(\"Which table do you want to overwrite the data?\\n 1. lyft_data\\n 2. uber_data\\n 3. weather_data\")\n",
    "    if user_input in ['1', '2', '3']:  # Check if the input is valid\n",
    "        print(f\"Valid input received: {user_input}\")\n",
    "        break  # Exit the loop if the input is valid\n",
    "    else:\n",
    "        print(\"Invalid input. Please try again.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid input received: 3\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:44.926479Z",
     "start_time": "2024-11-20T20:52:34.394428Z"
    }
   },
   "source": [
    "if user_input == '1': \n",
    "    table_id = \"lyft_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    authorization = input(\"Are you sure to over write data? Type 'OVERWRITE' to proceed.\")\n",
    "    if authorization == 'OVERWRITE':\n",
    "        overWriteDataToTable(lyft_df, table_ref)\n",
    "    else:\n",
    "        print(\"Action aborted\")\n",
    "if user_input == '2':\n",
    "    table_id = \"uber_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    authorization = input(\"Are you sure to over write data? Type 'OVERWRITE' to proceed.\")\n",
    "    if authorization == 'OVERWRITE':\n",
    "        overWriteDataToTable(uber_df, table_ref)\n",
    "    else:\n",
    "        print(\"Action aborted\")\n",
    "if user_input == '3':\n",
    "    table_id = 'weather_data'\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    authorization = input(\"Are you sure to over write data? Type 'OVERWRITE' to proceed.\")\n",
    "    if authorization == 'OVERWRITE':\n",
    "        overWriteDataToTable(weather_df, table_ref)\n",
    "    else:\n",
    "        print(\"Action aborted\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over written 637976 rows to the table weather_data in dataset uberFareEstimation.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
