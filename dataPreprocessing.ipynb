{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:55:29.666518Z",
     "start_time": "2024-11-20T20:55:29.033646Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# reading cab rides data into dataframe\n",
    "rides_df = pd.read_csv('dataOriginal/cab_rides.csv')\n",
    "\n",
    "# reading weather data into dataframe\n",
    "weather_df = pd.read_csv('dataOriginal/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:55:29.796260Z",
     "start_time": "2024-11-20T20:55:29.746742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting Unix timestamp to Datetime, truncated to nearest hour\n",
    "rides_df = rides_df.copy()\n",
    "rides_df['time_stamp'] = pd.to_datetime(rides_df['time_stamp'], unit='ms').dt.floor('30min')\n",
    "weather_df = weather_df.copy()\n",
    "weather_df['time_stamp'] = pd.to_datetime(rides_df['time_stamp'], unit='ms').dt.round('30min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693071, 10)\n",
      "(6276, 8)\n"
     ]
    }
   ],
   "source": [
    "print(rides_df.shape)\n",
    "print(weather_df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4147, 8)\n"
     ]
    }
   ],
   "source": [
    "weather_df = weather_df.drop_duplicates(subset=['time_stamp', 'location'], keep='first')\n",
    "print(weather_df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:55:30.389129Z",
     "start_time": "2024-11-20T20:55:30.256951Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing Null Values from rides dataframe \n",
    "rides_df = rides_df.dropna()\n",
    "\n",
    "# Remove product id from rides df\n",
    "rides_df = rides_df.drop('product_id', axis = 1)\n",
    "\n",
    "# Converting id from 30 characters -> 0, 1, 2, etc..\n",
    "rides_df['id'] = range(len(rides_df))\n",
    "\n",
    "\n",
    "# converting null values in (rain) column to 0 (No rain)\n",
    "weather_df['rain'] = weather_df['rain'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:55:31.882626Z",
     "start_time": "2024-11-20T20:55:31.775372Z"
    }
   },
   "outputs": [],
   "source": [
    "# splitting dataframes into Uber and Lyft\n",
    "uber_df = rides_df[rides_df['cab_type'] == 'Uber']\n",
    "lyft_df = rides_df[rides_df['cab_type'] == 'Lyft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330568, 9)\n",
      "(307408, 9)\n"
     ]
    }
   ],
   "source": [
    "print(uber_df.shape)\n",
    "print(lyft_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:30.712215Z",
     "start_time": "2024-11-20T20:51:29.244726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in dataset uberFareEstimation:\n",
      "lyft_data\n",
      "uber_data\n",
      "weather_data\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client.from_service_account_json(\"secrets/serviceKey.json\")\n",
    "\n",
    "# Define the dataset reference\n",
    "project_id = \"idmpproject-441123\"\n",
    "dataset_id = \"uberFareEstimation\"\n",
    "dataset_ref = f\"{project_id}.{dataset_id}\"\n",
    "\n",
    "# List all tables in the dataset\n",
    "tablesList = []\n",
    "try:\n",
    "    tables = client.list_tables(dataset_ref)\n",
    "    print(f\"Tables in dataset {dataset_id}:\")\n",
    "    for table in tables:\n",
    "        tablesList.append(table.table_id)\n",
    "        print(table.table_id)\n",
    "except NotFound:\n",
    "    print(f\"Dataset {dataset_id} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:51:31.273418Z",
     "start_time": "2024-11-20T20:51:31.269869Z"
    }
   },
   "outputs": [],
   "source": [
    "rides_schema = [\n",
    "    bigquery.SchemaField(\"distance\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cab_type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"time_stamp\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"destination\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"source\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"price\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"surge_multiplier\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"name\", \"STRING\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "weather_schema = [\n",
    "    bigquery.SchemaField(\"temp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"location\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"clouds\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"pressure\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"rain\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"time_stamp\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"humidity\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"wind\", \"FLOAT\", mode=\"NULLABLE\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:25.959090Z",
     "start_time": "2024-11-20T20:52:25.952156Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'uber_data' not in tablesList:\n",
    "    table_id = \"uber_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    table_object = bigquery.Table(table_ref, schema=rides_schema)\n",
    "    try:\n",
    "        table = client.create_table(table_object)\n",
    "        print(f\"Created empty table {table_id} in dataset {dataset_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "\n",
    "if 'lyft_data' not in tablesList:\n",
    "    table_id = \"lyft_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    table_object = bigquery.Table(table_ref, schema=rides_schema)\n",
    "    try:\n",
    "        table = client.create_table(table_object)\n",
    "        print(f\"Created empty table {table_id} in dataset {dataset_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "        \n",
    "        \n",
    "if 'weather_data' not in tablesList:\n",
    "    table_id = \"weather_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    table_object = bigquery.Table(table_ref, schema=rides_schema)\n",
    "    try:\n",
    "        table = client.create_table(table_object)\n",
    "        print(f\"Created empty table {table_id} in dataset {dataset_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:26.963413Z",
     "start_time": "2024-11-20T20:52:26.960251Z"
    }
   },
   "outputs": [],
   "source": [
    "def overWriteDataToTable(dataFrameName, table_ref):\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\",  # Overwrite the data to the table\n",
    "    )\n",
    "    job = client.load_table_from_dataframe(dataFrameName, table_ref, job_config=job_config)\n",
    "\n",
    "    # Wait for the job to complete\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Over written {len(dataFrameName)} rows to the table {table_id} in dataset {dataset_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:31.756397Z",
     "start_time": "2024-11-20T20:52:28.538313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid input received: 3\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Which table do you want to overwrite the data?\\n 1. lyft_data\\n 2. uber_data\\n 3. weather_data\")\n",
    "    if user_input in ['1', '2', '3']:  # Check if the input is valid\n",
    "        print(f\"Valid input received: {user_input}\")\n",
    "        break  # Exit the loop if the input is valid\n",
    "    else:\n",
    "        print(\"Invalid input. Please try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:52:44.926479Z",
     "start_time": "2024-11-20T20:52:34.394428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over written 4147 rows to the table weather_data in dataset uberFareEstimation.\n"
     ]
    }
   ],
   "source": [
    "if user_input == '1': \n",
    "    table_id = \"lyft_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    authorization = input(\"Are you sure to over write data? Type 'OVERWRITE' to proceed.\")\n",
    "    if authorization == 'OVERWRITE':\n",
    "        overWriteDataToTable(lyft_df, table_ref)\n",
    "    else:\n",
    "        print(\"Action aborted\")\n",
    "if user_input == '2':\n",
    "    table_id = \"uber_data\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    authorization = input(\"Are you sure to over write data? Type 'OVERWRITE' to proceed.\")\n",
    "    if authorization == 'OVERWRITE':\n",
    "        overWriteDataToTable(uber_df, table_ref)\n",
    "    else:\n",
    "        print(\"Action aborted\")\n",
    "if user_input == '3':\n",
    "    table_id = 'weather_data'\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    authorization = input(\"Are you sure to over write data? Type 'OVERWRITE' to proceed.\")\n",
    "    if authorization == 'OVERWRITE':\n",
    "        overWriteDataToTable(weather_df, table_ref)\n",
    "    else:\n",
    "        print(\"Action aborted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
