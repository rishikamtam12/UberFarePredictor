{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T20:05:32.785112Z",
     "start_time": "2024-11-24T20:05:07.942989Z"
    }
   },
   "source": [
    "from google.cloud import bigquery\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize BigQuery Client\n",
    "client = bigquery.Client.from_service_account_json(\"secrets/serviceKey.json\")\n",
    "\n",
    "project_id = \"idmpproject-441123\"\n",
    "dataset_id = \"uberFareEstimation\"\n",
    "uber_table_id = 'uber_data'\n",
    "weather_table_id = 'weather_data'\n",
    "\n",
    "table_path = f\"{project_id}.{dataset_id}.{uber_table_id}\"\n",
    "\n",
    "# Define the query\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{table_path}`\n",
    "\"\"\"\n",
    "\n",
    "# Run the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Wait for the query to complete and fetch results\n",
    "results = query_job.result()\n",
    "\n",
    "df = results.to_dataframe()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T20:16:23.567928Z",
     "start_time": "2024-11-24T20:16:23.532533Z"
    }
   },
   "source": [
    "# importing libraries for machine learning\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, r2_score\n",
    "\n",
    "\n",
    "# change features depending on correlation metrics/what will make model most accurate\n",
    "features = ['distance', 'cab_type', 'time_stamp', 'destination', 'source', 'surge_multiplier']\n",
    "\n",
    "# variable that is being predicted\n",
    "target_variable = 'price'\n",
    "\n",
    "# Extract X (features) and y (target) from the data\n",
    "X = df[features]\n",
    "y = df[target_variable]\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   distance cab_type          time_stamp         destination         source  \\\n",
       "0      0.94     Uber 2018-11-28 23:30:00           North End  North Station   \n",
       "1      0.94     Uber 2018-12-14 19:30:00           North End  North Station   \n",
       "2      0.63     Uber 2018-11-27 21:30:00  Financial District  South Station   \n",
       "3      0.63     Uber 2018-12-15 15:00:00  Financial District  South Station   \n",
       "4      0.63     Uber 2018-12-15 13:30:00  Financial District  South Station   \n",
       "\n",
       "   price  surge_multiplier      id      name  \n",
       "0    4.5               1.0   39765  UberPool  \n",
       "1    4.5               1.0  437984  UberPool  \n",
       "2    4.5               1.0    1644  UberPool  \n",
       "3    4.5               1.0   10780  UberPool  \n",
       "4    4.5               1.0   21598  UberPool  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>Uber</td>\n",
       "      <td>2018-11-28 23:30:00</td>\n",
       "      <td>North End</td>\n",
       "      <td>North Station</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39765</td>\n",
       "      <td>UberPool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.94</td>\n",
       "      <td>Uber</td>\n",
       "      <td>2018-12-14 19:30:00</td>\n",
       "      <td>North End</td>\n",
       "      <td>North Station</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>437984</td>\n",
       "      <td>UberPool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.63</td>\n",
       "      <td>Uber</td>\n",
       "      <td>2018-11-27 21:30:00</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>South Station</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1644</td>\n",
       "      <td>UberPool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.63</td>\n",
       "      <td>Uber</td>\n",
       "      <td>2018-12-15 15:00:00</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>South Station</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10780</td>\n",
       "      <td>UberPool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.63</td>\n",
       "      <td>Uber</td>\n",
       "      <td>2018-12-15 13:30:00</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>South Station</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21598</td>\n",
       "      <td>UberPool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T20:16:09.810052Z",
     "start_time": "2024-11-24T20:16:09.805499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# preprocessing for model\n",
    "\n",
    "# Convert 'time_stamp' into datetime format\n",
    "X['time_stamp'] = pd.to_datetime(X['time_stamp'])\n",
    "\n",
    "# Extract useful time-based features\n",
    "X['hour'] = X['time_stamp'].dt.hour\n",
    "X['day_of_week'] = X['time_stamp'].dt.dayofweek\n",
    "\n",
    "# Drop the original 'time_stamp' column as it's no longer needed\n",
    "X = X.drop('time_stamp', axis=1)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configures a ColumnTransformer to preprocess categorical features using OneHotEncoder\n",
    "# leaves numerical features unchanged for model training\n",
    "\n",
    "\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['cab_type', 'source', 'destination']\n",
    "numerical_features = ['distance', 'surge_multiplier', 'hour', 'day_of_week']\n",
    "\n",
    "# Set up the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the preprocessor to confirm setup\n",
    "print(preprocessor)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# splitting data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T20:54:38.616094Z",
     "start_time": "2024-11-24T20:54:38.608073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# creating pipeline and training the model\n",
    "\n",
    "# Set up the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a pipeline with preprocessing and the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rf_model)\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Pipeline training complete.\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T20:54:38.731511Z",
     "start_time": "2024-11-24T20:54:38.729866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# making predictions and evaluating model\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Evaluate the model using R² Score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score: {r2}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# getting importance of each feature in the model\n",
    "\n",
    "# Access the trained Random Forest model from the pipeline\n",
    "rf_model_trained = pipeline.named_steps['regressor']\n",
    "\n",
    "# Get feature importances\n",
    "feature_names = pipeline.named_steps['preprocessor'].transformers_[0][1].get_feature_names_out(categorical_features)\n",
    "all_features = list(feature_names) + numerical_features\n",
    "feature_importances = rf_model_trained.feature_importances_\n",
    "\n",
    "# Combine feature names and their importances into a DataFrame\n",
    "import pandas as pd\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
